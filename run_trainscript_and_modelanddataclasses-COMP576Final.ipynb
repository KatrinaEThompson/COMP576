{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1a3bcb-567d-484b-8c99-44d5f9816063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Per-pool normalization stats and weights ---\n",
      "AG_LIVE_CARB_ACRE         mean=24.5277 std=24.9427 weight=2.190703\n",
      "BG_LIVE_CARB_ACRE         mean=4.8776 std=5.6622 weight=0.497309\n",
      "DEAD_WOOD_CARB_ACRE       mean=7.8243 std=9.5084 weight=0.835121\n",
      "LITTER_CARB_ACRE          mean=4.5264 std=2.5066 weight=0.220153\n",
      "SOIL_ORG_CARB_ACRE        mean=45.3138 std=14.3086 weight=1.256715\n",
      "------------------------------------------------\n",
      "\n",
      "Loaded 20418 rows, matched 20418 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# install Libraries\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from model_and_data_classes_COMP576Final import (\n",
    "    FIAGSEDataset, \n",
    "    CNNEncoderRegressionHead, \n",
    "    ConditionalWeightedLoss, \n",
    "    TARGET_COLUMNS, \n",
    "    NUM_OUTPUTS\n",
    ")\n",
    "\n",
    "#from train_script import train, test, save_results, results_dir, epochs, writer\n",
    "#from train_script import train, test, writer, epochs, train_loader, test_loader, model, device\n",
    "from train_script_COMP576Final import train, test, writer, epochs, train_loader, test_loader, model, device, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c09301c-ade3-448f-a020-046e36367e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: F:\\BCarbon\\Notebooks\n",
      "PyTorch Device: cuda\n",
      "Total Epochs to Run: 30\n",
      "Total Train Samples: 16334\n",
      "Total Test Samples: 4084\n",
      "Model Architecture:\n",
      "CNNEncoderRegressionHead(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.15, inplace=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (regression_head): Sequential(\n",
      "    (0): Linear(in_features=25600, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"PyTorch Device: {device}\")\n",
    "print(f\"Total Epochs to Run: {epochs}\")\n",
    "print(f\"Total Train Samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Total Test Samples: {len(test_loader.dataset)}\")\n",
    "print(f\"Model Architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e527c3-d561-4ae5-bff9-87998fe30c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "Train Epoch 1 [0/16334] Loss: 36.794643\n",
      "Train Epoch 1 [6400/16334] Loss: 0.707709\n",
      "Train Epoch 1 [12800/16334] Loss: 0.653674\n",
      "--- Train Epoch 1 Finished. Average Loss: 4.936217 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.6561,  4.6348,  7.6491,  4.4969, 46.0489],\n",
      "        [26.0738,  4.6558,  7.4225,  4.6387, 46.6398],\n",
      "        [22.0247,  3.7068,  6.7215,  4.2952, 42.3409],\n",
      "        [20.1701,  3.7785,  6.2174,  4.0025, 45.9543],\n",
      "        [27.4694,  4.5845,  7.4732,  4.4605, 44.5738]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 1: 0.609542 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.2221\n",
      "RMSE: 12.0568\n",
      "MAE: 6.9417\n",
      "Bias: -0.2597\n",
      "*** Best model updated at Epoch 1 with R²=0.2221 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=14.6588 RMSE=21.3717 R²=0.2720 Bias=-0.5546\n",
      "BG_LIVE_CARB_ACRE         MAE=3.0464 RMSE=4.8305 R²=0.2691 Bias=-0.5009\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.8251 RMSE=8.0251 R²=0.2447 Bias=-0.5440\n",
      "LITTER_CARB_ACRE          MAE=1.6635 RMSE=2.2756 R²=0.1608 Bias=-0.1638\n",
      "SOIL_ORG_CARB_ACRE        MAE=10.4553 RMSE=13.1765 R²=0.1612 Bias=0.4879\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 2 [0/16334] Loss: 0.456759\n",
      "Train Epoch 2 [6400/16334] Loss: 0.479900\n",
      "Train Epoch 2 [12800/16334] Loss: 0.451360\n",
      "--- Train Epoch 2 Finished. Average Loss: 0.526365 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.9140,  5.0904,  7.6021,  4.5176, 44.4823],\n",
      "        [26.1163,  4.7436,  7.7562,  4.7759, 46.4275],\n",
      "        [21.0194,  3.9068,  6.2908,  4.0745, 41.9110],\n",
      "        [20.3729,  3.7821,  7.0659,  4.1886, 47.3853],\n",
      "        [28.8753,  5.2010,  7.7055,  4.4996, 44.9990]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 2: 0.606699 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.2301\n",
      "RMSE: 12.0658\n",
      "MAE: 6.9089\n",
      "Bias: -0.2071\n",
      "*** Best model updated at Epoch 2 with R²=0.2301 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=14.4638 RMSE=21.3729 R²=0.2719 Bias=-0.3991\n",
      "BG_LIVE_CARB_ACRE         MAE=3.0493 RMSE=4.8179 R²=0.2730 Bias=-0.3068\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.9961 RMSE=8.2669 R²=0.1985 Bias=-0.6100\n",
      "LITTER_CARB_ACRE          MAE=1.5901 RMSE=2.1784 R²=0.2310 Bias=-0.1313\n",
      "SOIL_ORG_CARB_ACRE        MAE=10.3843 RMSE=13.0838 R²=0.1729 Bias=0.4307\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 3 [0/16334] Loss: 0.459421\n",
      "Train Epoch 3 [6400/16334] Loss: 0.553713\n",
      "Train Epoch 3 [12800/16334] Loss: 0.530527\n",
      "--- Train Epoch 3 Finished. Average Loss: 0.502162 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.1492,  4.8168,  7.5773,  4.5294, 43.6281],\n",
      "        [23.1375,  4.4254,  7.5853,  4.5652, 45.7345],\n",
      "        [24.1110,  4.6544,  6.7121,  4.1185, 41.3561],\n",
      "        [17.8852,  3.5560,  6.4026,  3.7889, 49.8679],\n",
      "        [27.0343,  5.0042,  7.8521,  4.5765, 44.8757]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 3: 0.592286 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.2750\n",
      "RMSE: 11.7138\n",
      "MAE: 6.7446\n",
      "Bias: 0.0208\n",
      "*** Best model updated at Epoch 3 with R²=0.2750 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=14.0421 RMSE=20.6378 R²=0.3211 Bias=-0.2977\n",
      "BG_LIVE_CARB_ACRE         MAE=2.9535 RMSE=4.6062 R²=0.3354 Bias=-0.1858\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.9324 RMSE=8.0161 R²=0.2464 Bias=-0.2314\n",
      "LITTER_CARB_ACRE          MAE=1.5605 RMSE=2.1151 R²=0.2750 Bias=-0.1188\n",
      "SOIL_ORG_CARB_ACRE        MAE=10.1768 RMSE=12.9201 R²=0.1935 Bias=0.9598\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 4 [0/16334] Loss: 0.467237\n",
      "Train Epoch 4 [6400/16334] Loss: 0.541734\n",
      "Train Epoch 4 [12800/16334] Loss: 0.519657\n",
      "--- Train Epoch 4 Finished. Average Loss: 0.491625 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.7737,  5.0246,  7.7403,  4.4284, 43.3120],\n",
      "        [24.1529,  4.3707,  7.4252,  4.6490, 46.3625],\n",
      "        [23.4144,  4.3070,  6.5219,  4.0864, 42.4114],\n",
      "        [20.5665,  3.6362,  6.4894,  4.2972, 48.3503],\n",
      "        [26.3556,  4.7095,  7.9117,  4.6532, 45.5073]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 4: 0.580951 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3084\n",
      "RMSE: 11.4807\n",
      "MAE: 6.6155\n",
      "Bias: 0.0259\n",
      "*** Best model updated at Epoch 4 with R²=0.3084 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.9712 RMSE=20.3193 R²=0.3419 Bias=0.0354\n",
      "BG_LIVE_CARB_ACRE         MAE=2.8715 RMSE=4.4802 R²=0.3713 Bias=-0.2286\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.6841 RMSE=7.6404 R²=0.3154 Bias=-0.1781\n",
      "LITTER_CARB_ACRE          MAE=1.5361 RMSE=2.1004 R²=0.2851 Bias=-0.0888\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.9568 RMSE=12.6552 R²=0.2262 Bias=0.6021\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 5 [0/16334] Loss: 0.476586\n",
      "Train Epoch 5 [6400/16334] Loss: 0.482646\n",
      "Train Epoch 5 [12800/16334] Loss: 0.468047\n",
      "--- Train Epoch 5 Finished. Average Loss: 0.482274 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.7648,  5.1069,  7.7527,  4.5435, 44.1257],\n",
      "        [22.1689,  4.0295,  6.7595,  4.4351, 46.1064],\n",
      "        [24.4274,  4.5209,  6.3442,  3.8064, 40.0337],\n",
      "        [15.1561,  2.8155,  4.7452,  4.0394, 49.1383],\n",
      "        [25.9341,  4.6639,  7.7342,  4.6101, 44.5277]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 5: 0.560086 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3024\n",
      "RMSE: 11.4330\n",
      "MAE: 6.3777\n",
      "Bias: -0.5837\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.2741 RMSE=20.2276 R²=0.3479 Bias=-1.7697\n",
      "BG_LIVE_CARB_ACRE         MAE=2.7920 RMSE=4.5920 R²=0.3395 Bias=-0.5639\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.4925 RMSE=7.7773 R²=0.2906 Bias=-0.9462\n",
      "LITTER_CARB_ACRE          MAE=1.5061 RMSE=2.1063 R²=0.2811 Bias=-0.1538\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.7740 RMSE=12.4573 R²=0.2503 Bias=0.5593\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 6 [0/16334] Loss: 0.522701\n",
      "Train Epoch 6 [6400/16334] Loss: 0.475434\n",
      "Train Epoch 6 [12800/16334] Loss: 0.485531\n",
      "--- Train Epoch 6 Finished. Average Loss: 0.474024 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.4574,  4.8196,  7.6384,  4.5478, 43.8698],\n",
      "        [21.5693,  3.9506,  6.4127,  4.1602, 46.4201],\n",
      "        [21.9947,  3.8297,  6.2972,  3.7742, 41.3621],\n",
      "        [16.1232,  3.0670,  5.3124,  4.3886, 51.6823],\n",
      "        [23.6061,  4.2483,  7.0974,  4.6099, 45.5136]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 6: 0.577801 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.2754\n",
      "RMSE: 11.8394\n",
      "MAE: 6.5799\n",
      "Bias: -0.4959\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=14.0162 RMSE=21.2368 R²=0.2812 Bias=-1.7812\n",
      "BG_LIVE_CARB_ACRE         MAE=2.8716 RMSE=4.7003 R²=0.3080 Bias=-0.6008\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.6302 RMSE=7.9047 R²=0.2672 Bias=-0.7939\n",
      "LITTER_CARB_ACRE          MAE=1.5146 RMSE=2.1098 R²=0.2787 Bias=-0.1704\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.8059 RMSE=12.5335 R²=0.2411 Bias=0.9157\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 7 [0/16334] Loss: 0.444427\n",
      "Train Epoch 7 [6400/16334] Loss: 0.509344\n",
      "Train Epoch 7 [12800/16334] Loss: 0.527374\n",
      "--- Train Epoch 7 Finished. Average Loss: 0.469255 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.2066,  5.2051,  7.7883,  4.5124, 44.4943],\n",
      "        [22.5139,  4.0745,  6.7188,  4.5399, 47.8124],\n",
      "        [22.8261,  4.3279,  6.3275,  3.9892, 41.8898],\n",
      "        [16.6721,  3.0114,  5.6565,  4.4058, 52.0767],\n",
      "        [25.1428,  4.4937,  7.4395,  4.6827, 46.0563]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 7: 0.579509 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.2812\n",
      "RMSE: 11.7898\n",
      "MAE: 6.5994\n",
      "Bias: -0.3016\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=14.1548 RMSE=21.1898 R²=0.2843 Bias=-1.3763\n",
      "BG_LIVE_CARB_ACRE         MAE=2.9043 RMSE=4.6655 R²=0.3182 Bias=-0.4769\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.7171 RMSE=7.9573 R²=0.2574 Bias=-0.7803\n",
      "LITTER_CARB_ACRE          MAE=1.5328 RMSE=2.1050 R²=0.2820 Bias=-0.0967\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.6216 RMSE=12.3565 R²=0.2623 Bias=1.2717\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 8 [0/16334] Loss: 0.371858\n",
      "Train Epoch 8 [6400/16334] Loss: 0.484532\n",
      "Train Epoch 8 [12800/16334] Loss: 0.437166\n",
      "--- Train Epoch 8 Finished. Average Loss: 0.463984 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.6236,  5.0422,  7.4753,  4.4760, 42.3811],\n",
      "        [22.7238,  4.1715,  6.7593,  4.4389, 47.4998],\n",
      "        [22.5318,  4.0289,  6.2730,  3.6164, 40.6518],\n",
      "        [16.8842,  3.2276,  5.5822,  4.1879, 53.0524],\n",
      "        [23.2116,  4.2206,  6.9737,  4.6811, 46.0408]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 8: 0.566789 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3366\n",
      "RMSE: 11.4376\n",
      "MAE: 6.4545\n",
      "Bias: -0.0479\n",
      "*** Best model updated at Epoch 8 with R²=0.3366 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.9873 RMSE=20.5209 R²=0.3288 Bias=-0.7234\n",
      "BG_LIVE_CARB_ACRE         MAE=2.8745 RMSE=4.5539 R²=0.3504 Bias=-0.3585\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.5503 RMSE=7.4947 R²=0.3412 Bias=-0.4404\n",
      "LITTER_CARB_ACRE          MAE=1.4146 RMSE=1.9516 R²=0.3828 Bias=-0.0626\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.3773 RMSE=12.1992 R²=0.2810 Bias=1.3848\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 9 [0/16334] Loss: 0.452787\n",
      "Train Epoch 9 [6400/16334] Loss: 0.493223\n",
      "Train Epoch 9 [12800/16334] Loss: 0.439286\n",
      "--- Train Epoch 9 Finished. Average Loss: 0.460178 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.2304,  5.0257,  7.5667,  4.5232, 41.5935],\n",
      "        [22.1368,  4.0550,  6.8123,  4.5954, 46.9012],\n",
      "        [23.7536,  4.4281,  6.4864,  3.6140, 41.3929],\n",
      "        [16.2701,  3.0856,  5.3402,  4.4330, 50.8925],\n",
      "        [24.0709,  4.3185,  7.0685,  4.7205, 45.4356]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 9: 0.560230 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3581\n",
      "RMSE: 11.1908\n",
      "MAE: 6.3800\n",
      "Bias: -0.0220\n",
      "*** Best model updated at Epoch 9 with R²=0.3581 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.5545 RMSE=19.8545 R²=0.3717 Bias=-0.4155\n",
      "BG_LIVE_CARB_ACRE         MAE=2.7846 RMSE=4.3769 R²=0.4000 Bias=-0.3028\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.5036 RMSE=7.3082 R²=0.3736 Bias=-0.3150\n",
      "LITTER_CARB_ACRE          MAE=1.4284 RMSE=1.9514 R²=0.3829 Bias=-0.0197\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.5706 RMSE=12.3527 R²=0.2628 Bias=0.9707\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 10 [0/16334] Loss: 0.421618\n",
      "Train Epoch 10 [6400/16334] Loss: 0.518922\n",
      "Train Epoch 10 [12800/16334] Loss: 0.435406\n",
      "--- Train Epoch 10 Finished. Average Loss: 0.440993 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.7287,  5.1409,  7.6417,  4.4884, 41.2721],\n",
      "        [21.3613,  4.0080,  6.6171,  4.4777, 47.3290],\n",
      "        [23.7650,  4.4768,  6.1681,  3.5981, 40.8745],\n",
      "        [15.4907,  2.9143,  5.1432,  4.2590, 51.6288],\n",
      "        [22.1045,  4.0394,  6.5563,  4.7029, 46.1317]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 10: 0.535753 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4044\n",
      "RMSE: 10.7060\n",
      "MAE: 6.1013\n",
      "Bias: -0.1037\n",
      "*** Best model updated at Epoch 10 with R²=0.4044 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.9485 RMSE=18.8951 R²=0.4310 Bias=-0.6773\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6835 RMSE=4.1921 R²=0.4495 Bias=-0.3092\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2721 RMSE=7.0138 R²=0.4230 Bias=-0.3614\n",
      "LITTER_CARB_ACRE          MAE=1.3790 RMSE=1.9102 R²=0.4087 Bias=-0.0752\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.1685 RMSE=11.9588 R²=0.3091 Bias=0.9344\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 11 [0/16334] Loss: 0.372329\n",
      "Train Epoch 11 [6400/16334] Loss: 0.397040\n",
      "Train Epoch 11 [12800/16334] Loss: 0.389530\n",
      "--- Train Epoch 11 Finished. Average Loss: 0.433356 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.6209,  5.0734,  7.1370,  4.3875, 39.9227],\n",
      "        [19.8893,  3.7177,  6.1290,  4.4872, 48.0865],\n",
      "        [21.2152,  3.9490,  5.6207,  3.0183, 38.7139],\n",
      "        [15.6267,  2.6821,  4.5609,  4.2372, 52.5091],\n",
      "        [21.9952,  4.0240,  6.5018,  4.7375, 45.3255]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 11: 0.544118 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3592\n",
      "RMSE: 11.2401\n",
      "MAE: 6.1962\n",
      "Bias: -0.5777\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.2798 RMSE=20.1607 R²=0.3522 Bias=-1.8382\n",
      "BG_LIVE_CARB_ACRE         MAE=2.7369 RMSE=4.4901 R²=0.3685 Bias=-0.5874\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.3813 RMSE=7.4586 R²=0.3475 Bias=-0.8156\n",
      "LITTER_CARB_ACRE          MAE=1.3578 RMSE=1.8965 R²=0.4172 Bias=-0.1078\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.1637 RMSE=11.9373 R²=0.3115 Bias=0.5044\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 12 [0/16334] Loss: 0.382015\n",
      "Train Epoch 12 [6400/16334] Loss: 0.436602\n",
      "Train Epoch 12 [12800/16334] Loss: 0.395354\n",
      "--- Train Epoch 12 Finished. Average Loss: 0.425799 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.3311,  5.0755,  7.4431,  4.4126, 41.0591],\n",
      "        [22.0906,  4.0140,  6.7259,  4.4189, 47.4227],\n",
      "        [19.7664,  3.5190,  5.3634,  3.2557, 40.2372],\n",
      "        [15.5782,  2.6256,  4.5278,  4.3931, 53.1917],\n",
      "        [21.7683,  4.0120,  6.3494,  4.6442, 45.1125]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 12: 0.538296 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3926\n",
      "RMSE: 10.8807\n",
      "MAE: 6.1303\n",
      "Bias: -0.1983\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.0887 RMSE=19.3422 R²=0.4037 Bias=-0.9187\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6893 RMSE=4.2537 R²=0.4333 Bias=-0.3674\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2599 RMSE=7.1059 R²=0.4078 Bias=-0.4775\n",
      "LITTER_CARB_ACRE          MAE=1.3587 RMSE=1.9118 R²=0.4077 Bias=-0.0903\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.1981 RMSE=11.9457 R²=0.3106 Bias=0.8960\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 13 [0/16334] Loss: 0.463598\n",
      "Train Epoch 13 [6400/16334] Loss: 0.423979\n",
      "Train Epoch 13 [12800/16334] Loss: 0.421207\n",
      "--- Train Epoch 13 Finished. Average Loss: 0.422681 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.3238,  5.2412,  7.4109,  4.4466, 41.3303],\n",
      "        [21.7706,  3.9309,  6.7413,  4.5797, 47.9107],\n",
      "        [18.4579,  3.0784,  4.9153,  3.0739, 39.4325],\n",
      "        [12.7032,  1.9859,  4.3865,  4.4409, 54.3629],\n",
      "        [22.4318,  4.1629,  6.7762,  4.7247, 46.2732]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 13: 0.537574 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3771\n",
      "RMSE: 11.0424\n",
      "MAE: 6.1218\n",
      "Bias: -0.3962\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=13.0671 RMSE=19.7373 R²=0.3791 Bias=-1.7808\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6575 RMSE=4.3378 R²=0.4106 Bias=-0.5640\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.3070 RMSE=7.2346 R²=0.3861 Bias=-0.6814\n",
      "LITTER_CARB_ACRE          MAE=1.3893 RMSE=1.9297 R²=0.3966 Bias=-0.1311\n",
      "SOIL_ORG_CARB_ACRE        MAE=9.1310 RMSE=11.9215 R²=0.3134 Bias=1.2297\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 14 [0/16334] Loss: 0.402584\n",
      "Train Epoch 14 [6400/16334] Loss: 0.399986\n",
      "Train Epoch 14 [12800/16334] Loss: 0.474003\n",
      "--- Train Epoch 14 Finished. Average Loss: 0.412125 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.7080,  5.2630,  7.2694,  4.1332, 38.9013],\n",
      "        [20.6475,  3.8582,  6.4103,  4.4432, 47.4300],\n",
      "        [20.3560,  3.3854,  4.9305,  2.7909, 38.8420],\n",
      "        [14.7163,  2.3750,  4.8862,  4.2444, 52.8565],\n",
      "        [22.3227,  4.0416,  6.5998,  4.6588, 45.2622]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 14: 0.523075 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4321\n",
      "RMSE: 10.5607\n",
      "MAE: 5.9568\n",
      "Bias: -0.0849\n",
      "*** Best model updated at Epoch 14 with R²=0.4321 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.8377 RMSE=18.8024 R²=0.4365 Bias=-0.8008\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6278 RMSE=4.1334 R²=0.4649 Bias=-0.3492\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2192 RMSE=6.8532 R²=0.4492 Bias=-0.2535\n",
      "LITTER_CARB_ACRE          MAE=1.3159 RMSE=1.8289 R²=0.4580 Bias=-0.0462\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.7223 RMSE=11.5750 R²=0.3527 Bias=1.0588\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 15 [0/16334] Loss: 0.390628\n",
      "Train Epoch 15 [6400/16334] Loss: 0.422302\n",
      "Train Epoch 15 [12800/16334] Loss: 0.401275\n",
      "--- Train Epoch 15 Finished. Average Loss: 0.407733 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[24.0278,  4.8113,  7.0183,  4.3421, 40.6974],\n",
      "        [21.0266,  3.8751,  6.4625,  4.5461, 47.8462],\n",
      "        [23.6747,  4.2436,  6.3157,  3.6107, 41.3451],\n",
      "        [14.2519,  2.4059,  4.6655,  4.0199, 53.2816],\n",
      "        [21.7659,  4.0214,  6.6863,  4.7137, 45.9980]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 15: 0.528265 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.3912\n",
      "RMSE: 10.9919\n",
      "MAE: 6.0155\n",
      "Bias: -0.5416\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.9923 RMSE=19.7824 R²=0.3763 Bias=-2.3241\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6516 RMSE=4.3517 R²=0.4068 Bias=-0.6412\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2531 RMSE=7.2227 R²=0.3882 Bias=-0.7305\n",
      "LITTER_CARB_ACRE          MAE=1.3353 RMSE=1.8621 R²=0.4381 Bias=-0.0810\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.7831 RMSE=11.6165 R²=0.3481 Bias=1.1297\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 16 [0/16334] Loss: 0.385202\n",
      "Train Epoch 16 [6400/16334] Loss: 0.367260\n",
      "Train Epoch 16 [12800/16334] Loss: 0.454023\n",
      "--- Train Epoch 16 Finished. Average Loss: 0.400101 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[28.8560,  5.7687,  7.8283,  4.4222, 41.9375],\n",
      "        [22.4916,  4.0348,  6.8137,  4.6596, 47.5055],\n",
      "        [28.6036,  5.4008,  7.0739,  3.7117, 43.1532],\n",
      "        [16.5189,  2.8216,  5.0944,  4.2639, 52.0180],\n",
      "        [23.4561,  4.2875,  7.0085,  4.5883, 44.6554]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 16: 0.528310 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4111\n",
      "RMSE: 10.7421\n",
      "MAE: 6.0165\n",
      "Bias: -0.2438\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.9182 RMSE=19.1480 R²=0.4156 Bias=-0.8460\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6369 RMSE=4.2391 R²=0.4371 Bias=-0.4116\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2464 RMSE=7.0268 R²=0.4209 Bias=-0.5166\n",
      "LITTER_CARB_ACRE          MAE=1.3150 RMSE=1.8541 R²=0.4429 Bias=-0.0731\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.9065 RMSE=11.6901 R²=0.3398 Bias=0.6580\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 17 [0/16334] Loss: 0.376520\n",
      "Train Epoch 17 [6400/16334] Loss: 0.385613\n",
      "Train Epoch 17 [12800/16334] Loss: 0.401293\n",
      "--- Train Epoch 17 Finished. Average Loss: 0.395276 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.3627,  5.2535,  7.4358,  4.4100, 41.9877],\n",
      "        [21.7062,  3.9753,  6.5514,  4.6646, 47.9784],\n",
      "        [23.1043,  4.0253,  6.3450,  3.5593, 42.0908],\n",
      "        [15.9124,  2.7912,  4.8940,  4.3034, 52.2968],\n",
      "        [23.4376,  4.3496,  6.9655,  4.5563, 44.9791]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 17: 0.525251 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4202\n",
      "RMSE: 10.6813\n",
      "MAE: 5.9807\n",
      "Bias: -0.2498\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.8395 RMSE=18.9992 R²=0.4247 Bias=-0.9923\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6130 RMSE=4.1786 R²=0.4531 Bias=-0.4105\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.2076 RMSE=7.0184 R²=0.4223 Bias=-0.5342\n",
      "LITTER_CARB_ACRE          MAE=1.2943 RMSE=1.8222 R²=0.4619 Bias=-0.0468\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.8911 RMSE=11.6891 R²=0.3399 Bias=0.7692\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 18 [0/16334] Loss: 0.403964\n",
      "Train Epoch 18 [6400/16334] Loss: 0.358178\n",
      "Train Epoch 18 [12800/16334] Loss: 0.370617\n",
      "--- Train Epoch 18 Finished. Average Loss: 0.386633 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[23.1045,  3.9816,  6.8103,  4.1512, 39.1991],\n",
      "        [20.6406,  3.7740,  6.2915,  4.5373, 47.3525],\n",
      "        [18.6248,  3.3348,  5.1533,  3.1505, 38.4911],\n",
      "        [12.8617,  2.0972,  3.9699,  4.2749, 52.0940],\n",
      "        [20.8428,  3.7475,  6.2764,  4.5838, 44.7498]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 18: 0.522038 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4072\n",
      "RMSE: 10.9158\n",
      "MAE: 5.9442\n",
      "Bias: -0.9098\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.8775 RMSE=19.6755 R²=0.3830 Bias=-2.7195\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6280 RMSE=4.3469 R²=0.4082 Bias=-0.7784\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.1676 RMSE=7.1717 R²=0.3968 Bias=-1.0263\n",
      "LITTER_CARB_ACRE          MAE=1.2582 RMSE=1.7780 R²=0.4877 Bias=-0.1117\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.7277 RMSE=11.4853 R²=0.3627 Bias=0.1399\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 19 [0/16334] Loss: 0.373441\n",
      "Train Epoch 19 [6400/16334] Loss: 0.336937\n",
      "Train Epoch 19 [12800/16334] Loss: 0.318344\n",
      "--- Train Epoch 19 Finished. Average Loss: 0.380428 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[26.9910,  5.0019,  7.5159,  4.5299, 42.3401],\n",
      "        [21.7153,  4.0342,  6.5199,  4.7190, 49.2782],\n",
      "        [26.9234,  4.7314,  7.0525,  3.4608, 45.2622],\n",
      "        [16.1736,  2.7451,  5.0634,  4.3591, 51.1461],\n",
      "        [20.5565,  3.7326,  5.8361,  4.4950, 44.0386]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 19: 0.513011 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4555\n",
      "RMSE: 10.3486\n",
      "MAE: 5.8420\n",
      "Bias: 0.0672\n",
      "*** Best model updated at Epoch 19 with R²=0.4555 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.5398 RMSE=18.3314 R²=0.4644 Bias=-0.0227\n",
      "BG_LIVE_CARB_ACRE         MAE=2.5626 RMSE=3.9875 R²=0.5020 Bias=-0.1427\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.1065 RMSE=6.8074 R²=0.4565 Bias=-0.2255\n",
      "LITTER_CARB_ACRE          MAE=1.2693 RMSE=1.7737 R²=0.4902 Bias=0.0012\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.6745 RMSE=11.4676 R²=0.3647 Bias=0.7422\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 20 [0/16334] Loss: 0.358608\n",
      "Train Epoch 20 [6400/16334] Loss: 0.388962\n",
      "Train Epoch 20 [12800/16334] Loss: 0.355692\n",
      "--- Train Epoch 20 Finished. Average Loss: 0.372121 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[30.9226,  6.3873,  8.2787,  4.3014, 41.8345],\n",
      "        [20.9496,  3.8103,  6.4073,  4.5446, 47.8420],\n",
      "        [25.2129,  4.3036,  6.1947,  3.0236, 42.2082],\n",
      "        [15.2541,  2.5520,  4.8948,  4.2585, 52.8300],\n",
      "        [23.0961,  4.1787,  6.5052,  4.5997, 44.0407]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 20: 0.513144 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4246\n",
      "RMSE: 10.6297\n",
      "MAE: 5.8434\n",
      "Bias: -0.4463\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.4882 RMSE=18.9607 R²=0.4270 Bias=-1.4224\n",
      "BG_LIVE_CARB_ACRE         MAE=2.5362 RMSE=4.1458 R²=0.4617 Bias=-0.4652\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.1483 RMSE=7.0644 R²=0.4147 Bias=-0.6152\n",
      "LITTER_CARB_ACRE          MAE=1.2768 RMSE=1.8292 R²=0.4578 Bias=-0.1386\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.7121 RMSE=11.4953 R²=0.3616 Bias=0.4438\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 21 [0/16334] Loss: 0.341584\n",
      "Train Epoch 21 [6400/16334] Loss: 0.390273\n",
      "Train Epoch 21 [12800/16334] Loss: 0.361846\n",
      "--- Train Epoch 21 Finished. Average Loss: 0.364398 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.9961,  5.1589,  7.3932,  4.6116, 41.2100],\n",
      "        [21.0534,  3.8721,  6.4324,  4.6749, 48.1236],\n",
      "        [20.2248,  3.3482,  6.1825,  2.9489, 36.7735],\n",
      "        [13.2797,  2.0606,  3.9654,  4.2513, 53.6186],\n",
      "        [20.6967,  3.8844,  5.8604,  4.6641, 44.0084]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 21: 0.498284 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4606\n",
      "RMSE: 10.2520\n",
      "MAE: 5.6735\n",
      "Bias: -0.2091\n",
      "*** Best model updated at Epoch 21 with R²=0.4606 ***\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.2077 RMSE=18.1473 R²=0.4751 Bias=-0.6923\n",
      "BG_LIVE_CARB_ACRE         MAE=2.5018 RMSE=3.9939 R²=0.5004 Bias=-0.3212\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.0132 RMSE=6.9148 R²=0.4392 Bias=-0.6065\n",
      "LITTER_CARB_ACRE          MAE=1.2427 RMSE=1.7559 R²=0.5004 Bias=-0.0546\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.3444 RMSE=11.2606 R²=0.3874 Bias=0.6569\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 22 [0/16334] Loss: 0.313134\n",
      "Train Epoch 22 [6400/16334] Loss: 0.368897\n",
      "Train Epoch 22 [12800/16334] Loss: 0.409777\n",
      "--- Train Epoch 22 Finished. Average Loss: 0.356306 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[31.0532,  6.5201,  7.5936,  4.4621, 40.2082],\n",
      "        [21.9578,  4.0074,  6.5687,  4.6168, 48.2716],\n",
      "        [20.5070,  3.7374,  6.1157,  3.6748, 40.4935],\n",
      "        [15.5937,  2.6880,  4.8297,  4.2415, 52.1647],\n",
      "        [21.9005,  4.0561,  6.3267,  4.5171, 43.1073]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 22: 0.516440 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4323\n",
      "RMSE: 10.6368\n",
      "MAE: 5.8803\n",
      "Bias: -0.2442\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.7454 RMSE=19.1382 R²=0.4162 Bias=-1.1047\n",
      "BG_LIVE_CARB_ACRE         MAE=2.5920 RMSE=4.1390 R²=0.4634 Bias=-0.3326\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.1219 RMSE=6.8104 R²=0.4560 Bias=-0.3173\n",
      "LITTER_CARB_ACRE          MAE=1.2997 RMSE=1.8363 R²=0.4535 Bias=-0.0280\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.5812 RMSE=11.3840 R²=0.3739 Bias=0.5915\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 23 [0/16334] Loss: 0.374588\n",
      "Train Epoch 23 [6400/16334] Loss: 0.329389\n",
      "Train Epoch 23 [12800/16334] Loss: 0.329521\n",
      "--- Train Epoch 23 Finished. Average Loss: 0.353895 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[27.4285,  5.9765,  7.3856,  4.4756, 40.0388],\n",
      "        [22.6389,  4.2659,  6.8421,  4.7931, 48.6536],\n",
      "        [19.9396,  3.4335,  5.4411,  3.2761, 40.0786],\n",
      "        [16.0118,  2.6651,  4.9330,  4.3199, 53.4557],\n",
      "        [21.7863,  4.0144,  5.9599,  4.5007, 44.9845]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n",
      "\n",
      "--- Test Loss (normalized Fix-A) Epoch 23: 0.518325 ---\n",
      "\n",
      "--- GLOBAL METRICS ---\n",
      "R² (normalized): 0.4217\n",
      "RMSE: 10.7250\n",
      "MAE: 5.9019\n",
      "Bias: -0.5027\n",
      "\n",
      "--- PER-POOL METRICS ---\n",
      "AG_LIVE_CARB_ACRE         MAE=12.7931 RMSE=19.2495 R²=0.4094 Bias=-1.3481\n",
      "BG_LIVE_CARB_ACRE         MAE=2.6317 RMSE=4.2692 R²=0.4291 Bias=-0.4852\n",
      "DEAD_WOOD_CARB_ACRE       MAE=4.1844 RMSE=7.1223 R²=0.4051 Bias=-0.8452\n",
      "LITTER_CARB_ACRE          MAE=1.2457 RMSE=1.7713 R²=0.4916 Bias=-0.0505\n",
      "SOIL_ORG_CARB_ACRE        MAE=8.5911 RMSE=11.3764 R²=0.3747 Bias=0.2489\n",
      "\n",
      "Results saved to results\\Dec09_04-42-10_training_metrics.csv\n",
      "Train Epoch 24 [0/16334] Loss: 0.306526\n",
      "Train Epoch 24 [6400/16334] Loss: 0.283144\n",
      "Train Epoch 24 [12800/16334] Loss: 0.318494\n",
      "--- Train Epoch 24 Finished. Average Loss: 0.342311 ---\n",
      "\n",
      "--- FIRST BATCH DIAGNOSTICS ---\n",
      "Denorm target sample: tensor([[25.7993,  4.5830,  8.0807,  4.1906, 38.5245],\n",
      "        [30.8490,  5.3958,  9.0308,  4.5650, 54.3452],\n",
      "        [11.7672,  1.2991,  2.4523,  0.6174,  9.8762],\n",
      "        [ 5.0951,  0.9153,  1.0659,  4.3127, 64.2427],\n",
      "        [27.1605,  6.2638,  9.0060,  6.0386, 41.7272]], device='cuda:0')\n",
      "Denorm pred sample: tensor([[33.2889,  6.7492,  8.3735,  4.7385, 42.3048],\n",
      "        [21.7960,  4.0169,  6.5851,  4.5360, 48.5347],\n",
      "        [20.3746,  3.4218,  4.9538,  3.2556, 41.0433],\n",
      "        [13.4732,  2.3439,  4.0141,  4.4305, 54.4571],\n",
      "        [20.2153,  3.5680,  5.5416,  4.6616, 45.7050]], device='cuda:0')\n",
      "Per-pool stds: [24.942675   5.662203   9.508428   2.5065968 14.308567 ]\n",
      "Loss weights: [2.1907032  0.49730858 0.8351207  0.2201532  1.2567146 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    self._run()\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 775, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Users\\ericn\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 22] Invalid argument: b'F:\\\\BCarbon\\\\Notebooks\\\\runs\\\\Dec09_04-42-13_ForestCarbon_CNN\\\\events.out.tfevents.1765276933.Eve.24456.0'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: b'F:\\\\BCarbon\\\\Notebooks\\\\runs\\\\Dec09_04-42-13_ForestCarbon_CNN\\\\events.out.tfevents.1765276933.Eve.24456.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m      9\u001b[39m     train(epoch)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     avg_test_loss = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# If using ReduceLROnPlateau scheduler\u001b[39;00m\n\u001b[32m     12\u001b[39m     scheduler.step(avg_test_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mF:\\BCarbon\\Notebooks\\train_script.py:205\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(epoch)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# Log per-pool test loss\u001b[39;00m\n\u001b[32m    204\u001b[39m         pool_loss = np.mean(np.abs(output_denorm[v, i].cpu().numpy() - target_denorm[v, i].cpu().numpy()))\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest/pool_loss/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTARGET_COLUMNS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# global stacks\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_denorm.shape[\u001b[32m0\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:381\u001b[39m, in \u001b[36mSummaryWriter.add_scalar\u001b[39m\u001b[34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[39m\n\u001b[32m    376\u001b[39m torch._C._log_api_usage_once(\u001b[33m\"\u001b[39m\u001b[33mtensorboard.logging.add_scalar\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    378\u001b[39m summary = scalar(\n\u001b[32m    379\u001b[39m     tag, scalar_value, new_style=new_style, double_precision=double_precision\n\u001b[32m    380\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:115\u001b[39m, in \u001b[36mFileWriter.add_summary\u001b[39m\u001b[34m(self, summary, global_step, walltime)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add a `Summary` protocol buffer to the event file.\u001b[39;00m\n\u001b[32m    103\u001b[39m \n\u001b[32m    104\u001b[39m \u001b[33;03mThis method wraps the provided summary in an `Event` protocol buffer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    walltime (from time.time()) seconds after epoch\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    114\u001b[39m event = event_pb2.Event(summary=summary)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:99\u001b[39m, in \u001b[36mFileWriter.add_event\u001b[39m\u001b[34m(self, event, step, walltime)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# Make sure step is converted from numpy or other formats\u001b[39;00m\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# since protobuf might not convert depending on version\u001b[39;00m\n\u001b[32m     98\u001b[39m     event.step = \u001b[38;5;28mint\u001b[39m(step)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:117\u001b[39m, in \u001b[36mEventFileWriter.add_event\u001b[39m\u001b[34m(self, event)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, event_pb2.Event):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected an event_pb2.Event proto, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(event)\n\u001b[32m    116\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_async_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:171\u001b[39m, in \u001b[36m_AsyncWriter.write\u001b[39m\u001b[34m(self, bytestring)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Enqueue the given bytes to be written asychronously.\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Status of the worker should be checked under the lock to avoid\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# multiple threads passing the check and then switching just before\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# blocking on putting to the queue which might result in a deadlock.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_worker_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWriter is closed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:212\u001b[39m, in \u001b[36m_AsyncWriter._check_worker_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m exception = \u001b[38;5;28mself\u001b[39m._worker.exception\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\threading.py:1075\u001b[39m, in \u001b[36mThread._bootstrap_inner\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1072\u001b[39m     _sys.setprofile(_profile_hook)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1077\u001b[39m     \u001b[38;5;28mself\u001b[39m._invoke_excepthook(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:244\u001b[39m, in \u001b[36m_AsyncWriterThread.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    246\u001b[39m         \u001b[38;5;28mself\u001b[39m.exception = ex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:275\u001b[39m, in \u001b[36m_AsyncWriterThread._run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown_signal:\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_record_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m._has_pending_data = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m queue.Empty:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py:40\u001b[39m, in \u001b[36mRecordWriter.write\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     38\u001b[39m header_crc = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, masked_crc32c(header))\n\u001b[32m     39\u001b[39m footer_crc = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, masked_crc32c(data))\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_crc\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mfooter_crc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:775\u001b[39m, in \u001b[36mGFile.write\u001b[39m\u001b[34m(self, file_content)\u001b[39m\n\u001b[32m    771\u001b[39m         \u001b[38;5;28mself\u001b[39m.write_started = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    774\u001b[39m         \u001b[38;5;66;03m# append the later chunks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbinary_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# add to temp file, but wait for flush to write to final filesystem\u001b[39;00m\n\u001b[32m    778\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.write_temp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:167\u001b[39m, in \u001b[36mLocalFileSystem.append\u001b[39m\u001b[34m(self, filename, file_content, binary_mode)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mappend\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, file_content, binary_mode=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    160\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Append string file contents to a file.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \u001b[33;03m        binary_mode: bool, write as binary if True, otherwise text\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mab\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbinary_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.local\\share\\mamba\\envs\\COMP576\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:171\u001b[39m, in \u001b[36mLocalFileSystem._write\u001b[39m\u001b[34m(self, filename, file_content, mode)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, file_content, mode):\n\u001b[32m    170\u001b[39m     encoding = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    172\u001b[39m         compatify = compat.as_bytes \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;28;01melse\u001b[39;00m compat.as_text\n\u001b[32m    173\u001b[39m         f.write(compatify(file_content))\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: b'F:\\\\BCarbon\\\\Notebooks\\\\runs\\\\Dec09_04-42-13_ForestCarbon_CNN\\\\events.out.tfevents.1765276933.Eve.24456.0'"
     ]
    }
   ],
   "source": [
    "# execute \n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    avg_test_loss = test(epoch)\n",
    "    scheduler.step(avg_test_loss)\n",
    "\n",
    "# close tensorboard \n",
    "writer.close()\n",
    "print(\"Training finished and TensorBoard logs saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81e33d-1dbe-418b-a848-7f2d5f54bed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
